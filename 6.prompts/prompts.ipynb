{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baa29299-cbb9-4e5f-bcc5-c30630dd2693",
   "metadata": {},
   "source": [
    "# Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0772dd-4ac3-433b-81d8-23d5e7edc86b",
   "metadata": {},
   "source": [
    "### What’s a prompt\n",
    "\n",
    "A prompt is just the instruction you send to the model (system + user text). Think of it as “the script for the model.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81161264-8d81-494e-abfc-cd726744e599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result :  - The launch date has been rescheduled to Friday.\n",
      "- Team members should adjust their plans accordingly.\n",
      "- Further details will be provided as the new launch date approaches.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "\n",
    "prompt = \"\"\"You are a helpful assistant.\n",
    "Task: Summarize this email in 3 bullets.\n",
    "Email:\n",
    "Hi team, we moved the launch to Friday...\n",
    "\"\"\"\n",
    "result = llm.invoke(prompt)\n",
    "print(\"Result : \", result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4e768ab-a47e-451b-b190-1dec5251302e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant.\n",
      "Summarize the email in 3 bullets.\n",
      "Email:Hi team, we moved the launch to Friday...\n",
      "\n",
      "Result :  - The launch date has been rescheduled to Friday.\n",
      "- Team members should adjust their plans accordingly.\n",
      "- Further details or updates may follow as the new launch date approaches.\n"
     ]
    }
   ],
   "source": [
    "tmpl = PromptTemplate.from_template(\n",
    "    \"\"\"You are a helpful assistant.\n",
    "Summarize the email in {bullets} bullets.\n",
    "Email:{email}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompt = tmpl.format(bullets=3, email=\"Hi team, we moved the launch to Friday...\")\n",
    "print(prompt)                # inspect the rendered prompt\n",
    "result = llm.invoke(prompt)\n",
    "print(\"Result : \", result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd31b7a-61c0-4f6d-acc4-ee1a1c7d728e",
   "metadata": {},
   "source": [
    "### Partials (set defaults once, reuse later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a12d22e9-d2e6-47f8-8f50-261e5bba24ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_arabic :  [SystemMessage(content='You translate into Arabic. Keep tone and meaning.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Good morning', additional_kwargs={}, response_metadata={})]\n",
      "arabic_result :  صباح الخير\n",
      "------ Spanish Example----------\n",
      "prompt_spanish :  [SystemMessage(content='You translate into Spanish. Keep tone and meaning.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Where is the meeting room?', additional_kwargs={}, response_metadata={})]\n",
      "spanish_result :  ¿Dónde está la sala de reuniones?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "base = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You translate into {lang}. Keep tone and meaning.\"),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "to_arabic = base.partial(lang=\"Arabic\")\n",
    "to_spanish = base.partial(lang=\"Spanish\")\n",
    "\n",
    "prompt_arabic = to_arabic.format_messages(text=\"Good morning\")\n",
    "print(\"prompt_arabic : \",prompt_arabic)                # inspect the rendered prompt\n",
    "arabic_result = llm.invoke(prompt_arabic)\n",
    "print(\"arabic_result : \", arabic_result.content)\n",
    "\n",
    "# Spanish example\n",
    "print(\"------ Spanish Example----------\")\n",
    "prompt_spanish = to_spanish.format_messages(text=\"Where is the meeting room?\")\n",
    "print(\"prompt_spanish : \",prompt_spanish)                # inspect the rendered prompt\n",
    "spanish_result = llm.invoke(prompt_spanish)\n",
    "print(\"spanish_result : \", spanish_result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e483959f-bfdf-4d57-8e22-c760df6ba050",
   "metadata": {},
   "source": [
    "### Loading template from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdd52ab7-29ec-47e2-b6bb-132233e829e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant.\n",
      "Summarize the email in 3 bullets.\n",
      "Email :Hi team, we moved the launch to Friday...\n",
      "\n",
      "Constraints: Be concise; include dates; no speculation.\n",
      "Result :\n",
      "  - The launch has been rescheduled to Friday.\n",
      "- The team is informed of the change.\n",
      "- No additional details or reasons for the change are provided.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template_str = Path(\"template.txt\").read_text(encoding=\"utf-8\")\n",
    "file_prompt = PromptTemplate.from_template(template_str)\n",
    "# tmpl = file_prompt.format(bullets=3, email=\"Hi team, we moved the launch to Friday...\")\n",
    "\n",
    "\n",
    "# render\n",
    "prompt = tmpl.format(bullets=3, email=\"Hi team, we moved the launch to Friday...\")\n",
    "print(prompt)\n",
    "result = llm.invoke(prompt)\n",
    "print(\"Result :\\n \", result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e6a47-06f9-48e7-b538-f0d315cfceec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
