{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baa29299-cbb9-4e5f-bcc5-c30630dd2693",
   "metadata": {},
   "source": [
    "# Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0772dd-4ac3-433b-81d8-23d5e7edc86b",
   "metadata": {},
   "source": [
    "### What’s a prompt\n",
    "\n",
    "A prompt is just the instruction you send to the model (system + user text). Think of it as “the script for the model.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81161264-8d81-494e-abfc-cd726744e599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result :  - The launch date has been rescheduled to Friday.\n",
      "- Team members should adjust their plans accordingly.\n",
      "- Further details will be provided as the new launch date approaches.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "\n",
    "prompt = \"\"\"You are a helpful assistant.\n",
    "Task: Summarize this email in 3 bullets.\n",
    "Email:\n",
    "Hi team, we moved the launch to Friday...\n",
    "\"\"\"\n",
    "result = llm.invoke(prompt)\n",
    "print(\"Result : \", result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4e768ab-a47e-451b-b190-1dec5251302e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant.\n",
      "Summarize the email in 3 bullets.\n",
      "Email:Hi team, we moved the launch to Friday...\n",
      "\n",
      "Result :  - The launch date has been rescheduled to Friday.\n",
      "- Team members should adjust their plans accordingly.\n",
      "- Further details or updates may follow as the new launch date approaches.\n"
     ]
    }
   ],
   "source": [
    "tmpl = PromptTemplate.from_template(\n",
    "    \"\"\"You are a helpful assistant.\n",
    "Summarize the email in {bullets} bullets.\n",
    "Email:{email}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompt = tmpl.format(bullets=3, email=\"Hi team, we moved the launch to Friday...\")\n",
    "print(prompt)                # inspect the rendered prompt\n",
    "result = llm.invoke(prompt)\n",
    "print(\"Result : \", result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd31b7a-61c0-4f6d-acc4-ee1a1c7d728e",
   "metadata": {},
   "source": [
    "### Partials (set defaults once, reuse later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a12d22e9-d2e6-47f8-8f50-261e5bba24ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_arabic :  [SystemMessage(content='You translate into Arabic. Keep tone and meaning.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Good morning', additional_kwargs={}, response_metadata={})]\n",
      "arabic_result :  صباح الخير\n",
      "------ Spanish Example----------\n",
      "prompt_spanish :  [SystemMessage(content='You translate into Spanish. Keep tone and meaning.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Where is the meeting room?', additional_kwargs={}, response_metadata={})]\n",
      "spanish_result :  ¿Dónde está la sala de reuniones?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "base = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You translate into {lang}. Keep tone and meaning.\"),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "to_arabic = base.partial(lang=\"Arabic\")\n",
    "to_spanish = base.partial(lang=\"Spanish\")\n",
    "\n",
    "prompt_arabic = to_arabic.format_messages(text=\"Good morning\")\n",
    "print(\"prompt_arabic : \",prompt_arabic)                # inspect the rendered prompt\n",
    "arabic_result = llm.invoke(prompt_arabic)\n",
    "print(\"arabic_result : \", arabic_result.content)\n",
    "\n",
    "# Spanish example\n",
    "print(\"------ Spanish Example----------\")\n",
    "prompt_spanish = to_spanish.format_messages(text=\"Where is the meeting room?\")\n",
    "print(\"prompt_spanish : \",prompt_spanish)                # inspect the rendered prompt\n",
    "spanish_result = llm.invoke(prompt_spanish)\n",
    "print(\"spanish_result : \", spanish_result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e483959f-bfdf-4d57-8e22-c760df6ba050",
   "metadata": {},
   "source": [
    "### Loading template from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdd52ab7-29ec-47e2-b6bb-132233e829e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'templates/summary.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m file_prompt = PromptTemplate.from_template(template_str)\n\u001b[32m      6\u001b[39m tmpl = file_prompt.format(bullets=\u001b[32m3\u001b[39m, email=\u001b[33m\"\u001b[39m\u001b[33mHi team, we moved the launch to Friday...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m template_str = \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemplates/summary.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# build a PromptTemplate from the file content\u001b[39;00m\n\u001b[32m     11\u001b[39m tmpl = PromptTemplate.from_template(template_str)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.4/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:546\u001b[39m, in \u001b[36mPath.read_text\u001b[39m\u001b[34m(self, encoding, errors, newline)\u001b[39m\n\u001b[32m    543\u001b[39m \u001b[38;5;66;03m# Call io.text_encoding() here to ensure any warning is raised at an\u001b[39;00m\n\u001b[32m    544\u001b[39m \u001b[38;5;66;03m# appropriate stack level.\u001b[39;00m\n\u001b[32m    545\u001b[39m encoding = io.text_encoding(encoding)\n\u001b[32m--> \u001b[39m\u001b[32m546\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPathBase\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.4/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_abc.py:632\u001b[39m, in \u001b[36mPathBase.read_text\u001b[39m\u001b[34m(self, encoding, errors, newline)\u001b[39m\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, encoding=\u001b[38;5;28;01mNone\u001b[39;00m, errors=\u001b[38;5;28;01mNone\u001b[39;00m, newline=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    629\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    630\u001b[39m \u001b[33;03m    Open the file in text mode, read it, and close the file.\u001b[39;00m\n\u001b[32m    631\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m632\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    633\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m f.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.4/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:537\u001b[39m, in \u001b[36mPath.open\u001b[39m\u001b[34m(self, mode, buffering, encoding, errors, newline)\u001b[39m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m    536\u001b[39m     encoding = io.text_encoding(encoding)\n\u001b[32m--> \u001b[39m\u001b[32m537\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'templates/summary.txt'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template_str = Path(\"template.txt\").read_text(encoding=\"utf-8\")\n",
    "file_prompt = PromptTemplate.from_template(template_str)\n",
    "tmpl = file_prompt.format(bullets=3, email=\"Hi team, we moved the launch to Friday...\")\n",
    "\n",
    "\n",
    "# render\n",
    "prompt = tmpl.format(bullets=3, email=\"Hi team, we moved the launch to Friday...\")\n",
    "print(prompt)\n",
    "result = llm.invoke(prompt)\n",
    "print(\"Result : \", result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e6a47-06f9-48e7-b538-f0d315cfceec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
