{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb1cd2c9-4cc1-4400-b775-7daeb708beab",
   "metadata": {},
   "source": [
    "# Runnable \n",
    "\n",
    "\n",
    "LangChain’s most important idea isn’t a specific model—it’s the **Runnable**.\n",
    "\n",
    "A Runnable is just a tiny, consistent “block” that takes some input and produces some output—with the same controls everywhere:\n",
    "\n",
    "invoke(input) → run once (sync)\n",
    "\n",
    "ainvoke(input) → run once (async/await)\n",
    "\n",
    "batch([inputs]) → run many at once\n",
    "\n",
    "stream(input) / astream(input) → stream partial results (e.g., tokens)\n",
    "\n",
    "Think of a Runnable as a Lego piece with standard buttons. You can wrap almost anything—a function, an LLM, a retriever—so it all behaves the same way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85713936-8bc5-4c43-865b-cbb0f643a224",
   "metadata": {},
   "source": [
    "Runnable[Input, Output] is a generic abstract/base in langchain_core.runnables. \n",
    "You usually don’t subclass it directly—use helpers like RunnableLambda, \n",
    "or just use existing runnables (ChatPromptTemplate, ChatOpenAI, parsers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69d8a7d-5804-4d87-8a11-7e2e06bd42c9",
   "metadata": {},
   "source": [
    "## Mental “type” picture\n",
    "\n",
    "ChatPromptTemplate: Runnable[dict, list[BaseMessage]]\n",
    "\n",
    "ChatOpenAI: Runnable[list[BaseMessage], AIMessage]\n",
    "\n",
    "JsonOutputParser[T]: Runnable[str, T]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208da745-65a9-49c8-86c2-a03e06c4f8df",
   "metadata": {},
   "source": [
    "### invoke method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f852d915-5525-4211-ab97-78dbe30ff3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of the United Kingdom is London! It is a big and exciting city that is located in England, which is one of the countries in the UK. London is known for its famous landmarks like the Tower of London, Big Ben, and Buckingham Palace, where the Queen lives. It has lots of museums, parks, and even a giant Ferris wheel called the London Eye. People from all over the world visit London to see its sights and learn about its history. Here's a fun fact: London has a secret underground train system called the Tube, and it's one of the oldest in the world!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "response = model.invoke(\"What is capital of UK?  Give me answer in one paragraph, and give like you are teaching to 5 grade students. add one fun fact in the  end\")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2fad15-2ef8-4edc-ba7a-ce03dca70054",
   "metadata": {},
   "source": [
    "### batch method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a43dd0e2-0dbb-4d2a-8275-b30fa8165ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The capital of China is Beijing.\n",
      "- The capital of Spain is Madrid.\n"
     ]
    }
   ],
   "source": [
    "inputs = [\n",
    "    \"What is capital of China\",\n",
    "    \"What is capital of spain\"\n",
    "]\n",
    "responses = model.batch(inputs)\n",
    "for resp in responses:\n",
    "    print(\"-\", resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fe63f1-4243-4e2f-9ce8-fd6094e74aae",
   "metadata": {},
   "source": [
    "### Stream Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c18f3ff3-6c05-486e-b456-2ed822fb3991",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of the United Kingdom (UK) is London. London is a very big and busy city located in England. It is not just the political center of the UK but also a place full of history, culture, and fun things to do! In London, you can visit famous landmarks like the Big Ben clock tower, the Tower of London, and Buckingham Palace, where the Queen of England lives. Many people come from all over the world to see these amazing sights and learn more about English history.\n",
      "\n",
      "London is quite special because it has a mixture of old and new buildings, like ancient castles standing next to modern skyscrapers. It's a city where you can ride on red double-decker buses or take a boat ride on the River Thames. Did you know that London is home to the British Museum? It's one of the largest and most famous museums in the world, where you can see amazing treasures from ancient civilizations! Fun fact: London has a secret underground system called the \"Tube,\" which helps people travel around the city quickly and easily!\n",
      "-- end stream --\n"
     ]
    }
   ],
   "source": [
    "stream_response = model.stream(\"What is capital of UK?  Give me answer in two paragraph, and give like you are teaching to 5 grade students. add one fun fact in the  end\")\n",
    "\n",
    "for chunk in stream_response:\n",
    "    # chunk is a ChatGenerationChunk\n",
    "    print(chunk.content, end=\"\")\n",
    "print(\"\\n-- end stream --\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89d9e55-ed65-4c19-b934-a3081f304756",
   "metadata": {},
   "source": [
    "# Custom Runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2228bd76-c164-4e9c-b7e0-808579d099f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "to_upper = RunnableLambda(lambda s: s.upper())\n",
    "print(to_upper.invoke(\"hello\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17e49afb-3264-431b-98d3-008a5bd5efff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain RunnableLambda\n",
      "['a', 'b c']\n",
      "{'topic': 'embeddings', 'tone': 'friendly'}\n",
      "{'ok': True}\n",
      "prepped data {'topic': 'vector search', 'tone': 'friendly'}\n",
      "messages :  messages=[SystemMessage(content='Be concise.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Explain vector search in one sentence for a friendly audience.', additional_kwargs={}, response_metadata={})]\n",
      "Vector search is a method of finding similar items by comparing their numerical representations, or \"vectors,\" in a multi-dimensional space, making it easier to discover related content like images, text, or products.\n"
     ]
    }
   ],
   "source": [
    "# poetry add install  pydantic\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import json, datetime, asyncio\n",
    "\n",
    "# 1) String preprocessor (trim + collapse spaces)\n",
    "clean_text = RunnableLambda(lambda s: \" \".join(s.strip().split()))\n",
    "print(clean_text.invoke(\"  Hello   LangChain \\n RunnableLambda  \"))   # \"Hello LangChain RunnableLambda\"\n",
    "print(clean_text.batch([\"  a  \", \" b\\nc \"]))                          # ['a', 'b c']\n",
    "\n",
    "# 2) Dict enricher (add defaults)\n",
    "add_defaults = RunnableLambda(lambda d: {**d, \"tone\": d.get(\"tone\", \"friendly\")})\n",
    "print(add_defaults.invoke({\"topic\": \"embeddings\"}))\n",
    "# {'topic': 'embeddings', 'tone': 'friendly'}\n",
    "\n",
    "# 3) Simple JSON parser (raises on invalid JSON) + retry wrapper\n",
    "parse_json = RunnableLambda(lambda s: json.loads(s))\n",
    "robust_parse = parse_json.with_retry()   # retries on exceptions\n",
    "print(robust_parse.invoke('{\"ok\":true}'))  # {'ok': True}\n",
    "\n",
    "# 4) Async variant (add UTC timestamp)\n",
    "async def add_ts_async(d):\n",
    "    return {**d, \"ts\": datetime.datetime.utcnow().isoformat() + \"Z\"}\n",
    "\n",
    "add_ts = RunnableLambda(func=lambda d: {**d, \"ts\": \"sync\"}, afunc=add_ts_async)\n",
    "# print(asyncio.run(add_ts.ainvoke({\"topic\": \"runnable\"})))\n",
    "# {'topic': 'runnable', 'ts': '2025-08-27T10:11:12.345678Z'}\n",
    "\n",
    "# 5) Use RunnableLambda as a tiny pre-processor before a prompt/model call (no LCEL pipes)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Be concise.\"),\n",
    "    (\"human\", \"Explain {topic} in one sentence for a {tone} audience.\")\n",
    "])\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Prepare inputs → clean/enrich → build messages → invoke model\n",
    "user_input = {\"topic\": \"vector search\"}\n",
    "prepped = add_defaults.invoke(user_input)# adds tone\n",
    "print(\"prepped data\", prepped)\n",
    "messages = prompt.invoke(prepped)                       # prompt is a Runnable\n",
    "print(\"messages : \", messages)\n",
    "reply = llm.invoke(messages)                            # model is a Runnable\n",
    "print(reply.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb34b4db-e2a5-47b6-82f8-4aaa062ec22d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
